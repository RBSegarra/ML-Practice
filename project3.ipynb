{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZfTTt6m7W4q"
      },
      "source": [
        "## CPSC 483 (Section 02)\n",
        "\n",
        "### Fall 2021 - Project 3\n",
        "\n",
        "#### Group Members\n",
        "\n",
        "- William Huynh\n",
        "\n",
        "- Jake Sichley\n",
        "\n",
        "- Ricky Segarra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy2D8LDy7bkC"
      },
      "source": [
        "##**Experiment 1**: reading pandas.read.csv() to load and examine the data set from bank-additional-full.csv and then using head to examine the first 5 rows. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1tRElnXCvGV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "51b3303b-3c4a-454c-e912-9fc56362b58f"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_set = pd.read_csv(r\"bank-additional-full.csv\", sep=\";\")\n",
        "data_set.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>month</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>emp.var.rate</th>\n",
              "      <th>cons.price.idx</th>\n",
              "      <th>cons.conf.idx</th>\n",
              "      <th>euribor3m</th>\n",
              "      <th>nr.employed</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56</td>\n",
              "      <td>housemaid</td>\n",
              "      <td>married</td>\n",
              "      <td>basic.4y</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>261</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>57</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>149</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>226</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40</td>\n",
              "      <td>admin.</td>\n",
              "      <td>married</td>\n",
              "      <td>basic.6y</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>151</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>307</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age        job  marital  ... euribor3m nr.employed   y\n",
              "0   56  housemaid  married  ...     4.857      5191.0  no\n",
              "1   57   services  married  ...     4.857      5191.0  no\n",
              "2   37   services  married  ...     4.857      5191.0  no\n",
              "3   40     admin.  married  ...     4.857      5191.0  no\n",
              "4   56   services  married  ...     4.857      5191.0  no\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JAgC-k08YWG"
      },
      "source": [
        "##**Experiment 2**: Using sklearn.model.selection.train_test_split() to split the features and target values into separate training and tests sets. 90% of the data is teh training set and 10% is the testing. To make sure it's reproducible, we pass the ekyword argument random_state = (2021-10-25). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhPULR8EGt_9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# extract our testing, training set\n",
        "training_set, testing_set = train_test_split(data_set, train_size=0.9, random_state=(2021-10-25))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf2gNNiK_Z5l"
      },
      "source": [
        "##**Experiment 3**: Preprocess trainig sets by removing duraiton column and setting aside feature y in traiing and testing, and then dropping it from features.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "WT5HzKx_H78W",
        "outputId": "06b604ee-94ce-4255-ce81-6a94ed108315"
      },
      "source": [
        "# set aside our 'y'\n",
        "training_set_y = training_set['y']\n",
        "testing_set_y = testing_set['y']\n",
        "\n",
        "# drop ['duration'], ['y'] from our DataFrames\n",
        "training_set.drop(columns=['duration', 'y'], inplace=True)\n",
        "testing_set.drop(columns=['duration', 'y'], inplace=True)\n",
        "\n",
        "training_set.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>month</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>emp.var.rate</th>\n",
              "      <th>cons.price.idx</th>\n",
              "      <th>cons.conf.idx</th>\n",
              "      <th>euribor3m</th>\n",
              "      <th>nr.employed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22975</th>\n",
              "      <td>56</td>\n",
              "      <td>retired</td>\n",
              "      <td>married</td>\n",
              "      <td>professional.course</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>aug</td>\n",
              "      <td>mon</td>\n",
              "      <td>5</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.4</td>\n",
              "      <td>93.444</td>\n",
              "      <td>-36.1</td>\n",
              "      <td>4.965</td>\n",
              "      <td>5228.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14746</th>\n",
              "      <td>26</td>\n",
              "      <td>technician</td>\n",
              "      <td>single</td>\n",
              "      <td>professional.course</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>unknown</td>\n",
              "      <td>cellular</td>\n",
              "      <td>jul</td>\n",
              "      <td>wed</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.4</td>\n",
              "      <td>93.918</td>\n",
              "      <td>-42.7</td>\n",
              "      <td>4.957</td>\n",
              "      <td>5228.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12505</th>\n",
              "      <td>38</td>\n",
              "      <td>admin.</td>\n",
              "      <td>divorced</td>\n",
              "      <td>high.school</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>jul</td>\n",
              "      <td>mon</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.4</td>\n",
              "      <td>93.918</td>\n",
              "      <td>-42.7</td>\n",
              "      <td>4.960</td>\n",
              "      <td>5228.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6801</th>\n",
              "      <td>33</td>\n",
              "      <td>admin.</td>\n",
              "      <td>divorced</td>\n",
              "      <td>university.degree</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>wed</td>\n",
              "      <td>2</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18389</th>\n",
              "      <td>29</td>\n",
              "      <td>admin.</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>jul</td>\n",
              "      <td>thu</td>\n",
              "      <td>3</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.4</td>\n",
              "      <td>93.918</td>\n",
              "      <td>-42.7</td>\n",
              "      <td>4.968</td>\n",
              "      <td>5228.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       age         job   marital  ... cons.conf.idx euribor3m nr.employed\n",
              "22975   56     retired   married  ...         -36.1     4.965      5228.1\n",
              "14746   26  technician    single  ...         -42.7     4.957      5228.1\n",
              "12505   38      admin.  divorced  ...         -42.7     4.960      5228.1\n",
              "6801    33      admin.  divorced  ...         -36.4     4.857      5191.0\n",
              "18389   29      admin.   married  ...         -42.7     4.968      5228.1\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNcoS8d_tzBm"
      },
      "source": [
        "##**Experiment 4**: Making input variables described as \"bank client data as features\" using drop_first and pandas.get_dummies().\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "RU5LpZ-7Ly8C",
        "outputId": "631bf35a-6246-42e3-bbb7-122848c8307c"
      },
      "source": [
        "bank_client_data_columns = ['age', 'job', 'marital', 'education', 'default', 'housing', 'loan']\n",
        "\n",
        "# extract the columns labeled as 'bank client data' from our training & testing sets\n",
        "bank_client_data_training_set = training_set[bank_client_data_columns]\n",
        "bank_client_data_testing_set = testing_set[bank_client_data_columns]\n",
        "\n",
        "# encode our categorical variables\n",
        "encoded_training_set = pd.get_dummies(bank_client_data_training_set, drop_first=True)\n",
        "encoded_testing_set = pd.get_dummies(bank_client_data_testing_set, drop_first=True)\n",
        "\n",
        "encoded_training_set.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job_blue-collar</th>\n",
              "      <th>job_entrepreneur</th>\n",
              "      <th>job_housemaid</th>\n",
              "      <th>job_management</th>\n",
              "      <th>job_retired</th>\n",
              "      <th>job_self-employed</th>\n",
              "      <th>job_services</th>\n",
              "      <th>job_student</th>\n",
              "      <th>job_technician</th>\n",
              "      <th>job_unemployed</th>\n",
              "      <th>job_unknown</th>\n",
              "      <th>marital_married</th>\n",
              "      <th>marital_single</th>\n",
              "      <th>marital_unknown</th>\n",
              "      <th>education_basic.6y</th>\n",
              "      <th>education_basic.9y</th>\n",
              "      <th>education_high.school</th>\n",
              "      <th>education_illiterate</th>\n",
              "      <th>education_professional.course</th>\n",
              "      <th>education_university.degree</th>\n",
              "      <th>education_unknown</th>\n",
              "      <th>default_unknown</th>\n",
              "      <th>default_yes</th>\n",
              "      <th>housing_unknown</th>\n",
              "      <th>housing_yes</th>\n",
              "      <th>loan_unknown</th>\n",
              "      <th>loan_yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22975</th>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14746</th>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12505</th>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6801</th>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18389</th>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       age  job_blue-collar  ...  loan_unknown  loan_yes\n",
              "22975   56                0  ...             0         0\n",
              "14746   26                0  ...             1         0\n",
              "12505   38                0  ...             0         0\n",
              "6801    33                0  ...             0         0\n",
              "18389   29                0  ...             0         0\n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwvOMGyot29-"
      },
      "source": [
        "##**Experiment 5**: Using scikit-learn to fit a Categorical Naive Bayes classifiers on features in 4. Afterwards score it on training and tests sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTusDqP7NooP",
        "outputId": "2ea2c11c-e029-4afa-c2ae-6671333e9ae1"
      },
      "source": [
        "from sklearn.naive_bayes import CategoricalNB\n",
        "\n",
        "cnb = CategoricalNB()\n",
        "cnb.fit(encoded_training_set, training_set_y)\n",
        "\n",
        "print(cnb.score(encoded_training_set, training_set_y))\n",
        "print(cnb.score(encoded_testing_set, testing_set_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8818689470986538\n",
            "0.8788540907987376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP269Xvfu-fq"
      },
      "source": [
        "\n",
        "The two scores were : \n",
        "\n",
        "*   Training | 0.8818689470986538\n",
        "*   Testing  | 0.8788540907987376\n",
        "\n",
        "These classifiers are highly accurate since they are 88%. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LapUm9mIt74Q"
      },
      "source": [
        "##**Experiment 6**: Relooking at data in experiment 5 and finding how many categories there are. Then check if it's reasonable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIrBRZ2xW2tq",
        "outputId": "515ad87b-27ba-441c-f2af-b09926c032b7"
      },
      "source": [
        "# pull the age column out of our encoded training set\n",
        "age_series = encoded_training_set['age']\n",
        "\n",
        "print(len(age_series.unique()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMk7pek0vVEJ"
      },
      "source": [
        "There are 78 different categories. This is unreasonable because age has a wide range, and they can eb seperated into different categories. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtGaWNZ8uA6P"
      },
      "source": [
        "##**Experiment 7**: Splitting ages into bins, one per decade. Afterwards re-train classifier with the bins and check performance changes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adv0hYywY2HX",
        "outputId": "01782644-63cd-47ae-90ee-443644df4cbc"
      },
      "source": [
        "# define our decades\n",
        "decades = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "\n",
        "# verify we have 10 bins\n",
        "age_series_as_decades = pd.cut(bank_client_data_training_set['age'], bins=decades)\n",
        "print(age_series_as_decades.cat.categories.size)\n",
        "\n",
        "# replace the original age data with our binned age date\n",
        "bank_client_data_training_set_with_bins = bank_client_data_training_set.copy(deep=True)\n",
        "bank_client_data_training_set_with_bins['age'] = age_series_as_decades\n",
        "\n",
        "# repeat the process for our testing set\n",
        "age_series_as_decades = pd.cut(bank_client_data_testing_set['age'], bins=decades)\n",
        "bank_client_data_testing_set_with_bins = bank_client_data_testing_set.copy(deep=True)\n",
        "bank_client_data_testing_set_with_bins['age'] = age_series_as_decades"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMH87wlze47K",
        "outputId": "33e925e2-7309-4a6e-d32a-2526e347d2e5"
      },
      "source": [
        "# re-encode our data\n",
        "encoded_training_set_with_bins = pd.get_dummies(bank_client_data_training_set_with_bins, drop_first=True)\n",
        "encoded_testing_set_with_bins = pd.get_dummies(bank_client_data_testing_set_with_bins, drop_first=True)\n",
        "\n",
        "# retrain our classifier\n",
        "cnb = CategoricalNB()\n",
        "cnb.fit(encoded_training_set_with_bins, training_set_y)\n",
        "\n",
        "print(cnb.score(encoded_training_set_with_bins, training_set_y))\n",
        "print(cnb.score(encoded_testing_set_with_bins, testing_set_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.881437319593191\n",
            "0.8788540907987376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9xdmLxovlOT"
      },
      "source": [
        "The new scores are \n",
        "\n",
        "\n",
        "*   Training | 0.881437319593191          \n",
        "*   Testing  | 0.8788540907987376\n",
        "\n",
        "Comparing this to the results of number 5 we can see there is a marginal difference. The performance, as the training set becomes worse and the testing set stays the same. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMHJ8-CPuOi0"
      },
      "source": [
        "##**Experiment 8**: Repeating experiment (8) with a KNN classifier and comparing results. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhJkzX1te8H8",
        "outputId": "2bf22ddd-5297-476f-a856-0e6b3ff08ba2"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knb = KNeighborsClassifier()\n",
        "knb.fit(encoded_training_set, training_set_y)\n",
        "\n",
        "print(knb.score(encoded_training_set, training_set_y))\n",
        "print(knb.score(encoded_testing_set, testing_set_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8903935903315439\n",
            "0.8771546491866958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkKVVtVLxUcE"
      },
      "source": [
        "The scores from KNN are : \n",
        "\n",
        "\n",
        "*   Training | 0.8903935903315439\n",
        "*   Testing  | 0.8771546491866958\n",
        "\n",
        "Comparing it to the results from 5, the training set is slightly higher and and testing set is slgihtly lower. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGPfvAEpuWaN"
      },
      "source": [
        "##**Experiment 9**: Checking how many values in the test set have repsonse 0 and how many are repsonse 1. Checking the score if we assumed no customer has ever subscribed to the product. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeReMgGEiE2C",
        "outputId": "3a052f99-7c2d-4a40-f25a-1f6610f1c321"
      },
      "source": [
        "print(testing_set_y.value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no     3646\n",
            "yes     473\n",
            "Name: y, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "998u5g3_x5DI"
      },
      "source": [
        "The test set has 3646 0's and 473 1's. If we assumed that no customer ever subscribed to the rpoduct, the score would be high since the counts show that they most likely didn't subscribe. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7RRyUwtuS7K"
      },
      "source": [
        "##**Experiment 10**: Using numpy.zeros_like() to create a target vector that reprsents output of \"dumb classifier\" of 9. Then we create a confusion matrix and find the AUC. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QdKOlVakf0q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b9273c9-638f-4302-ecba-86dbed5a703a"
      },
      "source": [
        "from numpy import array\n",
        "from numpy import zeros_like\n",
        "\n",
        "# create a fake response series\n",
        "# training\n",
        "\n",
        "modified_training_set_y = zeros_like(training_set_y)\n",
        "modified_training_set_y[modified_training_set_y == 0] = 'no'\n",
        "\n",
        "print(knb.score(encoded_training_set, modified_training_set_y))\n",
        "\n",
        "# testing\n",
        "modified_testing_set_y = zeros_like(testing_set_y)\n",
        "modified_testing_set_y[modified_testing_set_y == 0] = 'no'\n",
        "\n",
        "print(knb.score(encoded_testing_set, modified_testing_set_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9718363052685532\n",
            "0.965768390386016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUWUfj3ahQFA",
        "outputId": "6743ccd9-9b87-4ec0-8220-8c86988a9a94"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# -- SECTION: DUMB CLASSIFIER --\n",
        "# ---- SUBSECTION: TRAINING -----\n",
        "\n",
        "# create a confusion matrix with our \"dumb\" classifier\n",
        "print(confusion_matrix(training_set_y, modified_training_set_y))\n",
        "\n",
        "# score our \"dumb\" confusion matrix\n",
        "modified_training_set_y[modified_training_set_y == 'no'] = 0\n",
        "\n",
        "print(roc_auc_score(training_set_y, modified_training_set_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[32902     0]\n",
            " [ 4167     0]]\n",
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_577O9qmy5QA"
      },
      "source": [
        "The confusion matrix is :\n",
        "  \n",
        "[32902     0]\n",
        "\n",
        "[ 4167     0]\n",
        "\n",
        "The AUC is 0.5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQ0Ow4HKuetA"
      },
      "source": [
        "##**Experiment 11**: Creating confusion matricies and computing the AUC for each of the classifiers in expermients 7 and 8. Then check performance. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqK6VOyAJhTY",
        "outputId": "942f482b-3696-4834-a4df-3928bb89bfcc"
      },
      "source": [
        "# -- SECTION: DUMB CLASSIFIER --\n",
        "# ---- SUBSECTION: TESTING -----\n",
        "\n",
        "# create a confusion matrix with our \"dumb\" classifier\n",
        "print(confusion_matrix(testing_set_y, modified_testing_set_y))\n",
        "\n",
        "# score our \"dumb\" confusion matrix\n",
        "modified_testing_set_y[modified_testing_set_y == 'no'] = 0\n",
        "\n",
        "print(roc_auc_score(testing_set_y, modified_testing_set_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3646    0]\n",
            " [ 473    0]]\n",
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b4Ndb8h08Ae"
      },
      "source": [
        "Dumb Classifier\n",
        "\n",
        "\n",
        "[3646    0]\n",
        "\n",
        "[ 473    0]\n",
        "\n",
        "0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD4ko_SQvMX7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a8febb9-d434-457b-87cc-fef41e8ead30"
      },
      "source": [
        "# -- SECTION: Categorical Naive Bayes CLASSIFIER --\n",
        "# ---- SUBSECTION: TRAINING -----\n",
        "\n",
        "# create a confusion matrix with our Categorical Naive Bayes classifier\n",
        "cnb_training_predictions = cnb.predict(encoded_training_set_with_bins)\n",
        "\n",
        "# create our cnb confusion matrix\n",
        "print(confusion_matrix(training_set_y, cnb_training_predictions))\n",
        "\n",
        "cnb_training_predictions[cnb_training_predictions == 'no'] = 0\n",
        "cnb_training_predictions[cnb_training_predictions == 'yes'] = 1\n",
        "cnb_training_predictions = cnb_training_predictions.astype(int)\n",
        "\n",
        "# score our cnb confusion matrix\n",
        "print(roc_auc_score(training_set_y, cnb_training_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[32173   729]\n",
            " [ 3666   501]]\n",
            "0.5490368368852783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahxZUgGCKxR4",
        "outputId": "a4a87078-3acc-44ed-bce4-632d31bcb486"
      },
      "source": [
        "# -- SECTION: Categorical Naive Bayes CLASSIFIER --\n",
        "# ---- SUBSECTION: TESTING -----\n",
        "\n",
        "# create a confusion matrix with our Categorical Naive Bayes classifier\n",
        "cnb_testing_predictions = cnb.predict(encoded_testing_set_with_bins)\n",
        "\n",
        "# create our cnb confusion matrix\n",
        "print(confusion_matrix(testing_set_y, cnb_testing_predictions))\n",
        "\n",
        "cnb_testing_predictions[cnb_testing_predictions == 'no'] = 0\n",
        "cnb_testing_predictions[cnb_testing_predictions == 'yes'] = 1\n",
        "cnb_testing_predictions = cnb_testing_predictions.astype(int)\n",
        "\n",
        "# score our cnb confusion matrix\n",
        "print(roc_auc_score(testing_set_y, cnb_testing_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3554   92]\n",
            " [ 407   66]]\n",
            "0.5571508757606297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67J7q3vy0cTN"
      },
      "source": [
        "Categorical Naive Bayes Classifier Confusion Matrix and AUC: \n",
        "\n",
        "TRAINING \n",
        "\n",
        "[32173   729]\n",
        "\n",
        "[ 3666   501]\n",
        "\n",
        "0.5490368368852783\n",
        "\n",
        "\n",
        "TESTING \n",
        "\n",
        "[3554   92]\n",
        "\n",
        "[ 407   66]\n",
        "\n",
        "0.5571508757606297\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXZ8JRwexYtX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ae3fe89-31eb-460f-b7ef-49191c9f78b6"
      },
      "source": [
        "# -- SECTION: KNeighbors CLASSIFIER --\n",
        "# ---- SUBSECTION: TRAINING -----\n",
        "\n",
        "# create a confusion matrix with our KNeighbors Classifier\n",
        "knb_training_predictions = knb.predict(encoded_training_set)\n",
        "\n",
        "# create our knb confusion matrix\n",
        "print(confusion_matrix(training_set_y, knb_training_predictions))\n",
        "\n",
        "knb_training_predictions[knb_training_predictions == 'no'] = 0\n",
        "knb_training_predictions[knb_training_predictions == 'yes'] = 1\n",
        "knb_training_predictions = knb_training_predictions.astype(int)\n",
        "\n",
        "# score our knb confusion matrix\n",
        "print(roc_auc_score(training_set_y, knb_training_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[32432   470]\n",
            " [ 3593   574]]\n",
            "0.5617320670877847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7fsKpyKL3Aa",
        "outputId": "b25d6ae6-11d9-4271-f5b0-95e4b445e24b"
      },
      "source": [
        "# -- SECTION: KNeighbors CLASSIFIER --\n",
        "# ---- SUBSECTION: TESTING -----\n",
        "\n",
        "# create a confusion matrix with our KNeighbors Classifier\n",
        "knb_testing_predictions = knb.predict(encoded_testing_set)\n",
        "\n",
        "# create our knb confusion matrix\n",
        "print(confusion_matrix(testing_set_y, knb_testing_predictions))\n",
        "\n",
        "knb_testing_predictions[knb_testing_predictions == 'no'] = 0\n",
        "knb_testing_predictions[knb_testing_predictions == 'yes'] = 1\n",
        "knb_testing_predictions = knb_testing_predictions.astype(int)\n",
        "\n",
        "# score our knb confusion matrix\n",
        "print(roc_auc_score(testing_set_y, knb_testing_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3559   87]\n",
            " [ 419   54]]\n",
            "0.5451515692716626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImVYmknb02Nd"
      },
      "source": [
        "KNN Classifier Confusion Matrix and AUC:\n",
        "\n",
        "TRAINING\n",
        "\n",
        "[32432   470]\n",
        "\n",
        "[ 3593   574]\n",
        "\n",
        "0.5617320670877847\n",
        "\n",
        "\n",
        "TESTING\n",
        "\n",
        "[3559   87]\n",
        "\n",
        "[ 419   54]\n",
        "\n",
        "0.5451515692716626\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGGN0AUE1gBh"
      },
      "source": [
        "These classifiers seem to be doing alright. The majority of the data resulted in a correct prediciton, but 4167 were type 2 errors.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LNOUSKFunK2"
      },
      "source": [
        "##**Experiment 12**: Working around imbalanced data with random oversampling, using pandas.DataFrame.where() and pandas.DataFrame.sample(). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hB6DDuMVMmU8",
        "outputId": "bbbe0c12-e763-4e6f-e0f6-a8c40283c0c4"
      },
      "source": [
        "# create a copy of our original data set\n",
        "balanced_data_set = data_set.copy(deep=True)\n",
        "# add a dummy column to allow for weight manipulation\n",
        "balanced_data_set['weights'] = balanced_data_set['y']\n",
        "\n",
        "# create pre-defined filters we can pass to pandas.DataFrame.where\n",
        "filter_yes = balanced_data_set['y'] == 'yes'\n",
        "filter_no = balanced_data_set['y'] == 'no'\n",
        "\n",
        "# extract the count of 'yes' and 'no' responses\n",
        "value_weights = balanced_data_set['y'].value_counts()\n",
        "# dynamically calculate our weights based on distribution\n",
        "adjusted_yes_weight = (value_weights[1]/(sum(value_weights)))\n",
        "adjusted_no_weight = 1 - adjusted_yes_weight\n",
        "\n",
        "# manipulate the values in our dummy weights column based on value\n",
        "balanced_data_set['weights'] = balanced_data_set['weights'].where(filter_yes, other=adjusted_yes_weight)\n",
        "balanced_data_set['weights'] = balanced_data_set['weights'].where(filter_no, other=adjusted_no_weight)\n",
        "\n",
        "# create a new, \"balanced\" training set by sampling the data set using our generated weights\n",
        "balanced_training_set = balanced_data_set.sample(n=len(training_set), weights=balanced_data_set['weights'], replace=True, random_state=(2021-10-25))\n",
        "\n",
        "print(balanced_training_set.head())\n",
        "print(balanced_training_set['y'].value_counts())\n",
        "\n",
        "# finally, drop our dummy column\n",
        "balanced_training_set.drop(columns=['weights'], inplace=True)\n",
        "\n",
        "# set aside our 'y'\n",
        "balanced_training_set_y = balanced_training_set['y']\n",
        "\n",
        "# drop ['duration'], ['y'] from our DataFrames\n",
        "balanced_training_set.drop(columns=['duration', 'y'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       age         job  marital  ... nr.employed    y   weights\n",
            "29898   38  technician   single  ...      5099.1   no  0.112654\n",
            "4731    37  technician   single  ...      5191.0   no  0.112654\n",
            "30861   34      admin.  married  ...      5099.1   no  0.112654\n",
            "39531   30      admin.   single  ...      5008.7  yes  0.887346\n",
            "28793   32      admin.   single  ...      5099.1   no  0.112654\n",
            "\n",
            "[5 rows x 22 columns]\n",
            "yes    18536\n",
            "no     18533\n",
            "Name: y, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co6v_adiurtf"
      },
      "source": [
        "##**Experiment 13**: Retraining both classifiers on balanced training sets, finding score, confusion matrix, and AUC for each, and then comparing performaence between classifiers. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3_e9BpljlsD",
        "outputId": "9a5d8fdd-2f9b-4721-a095-e4470d3f313f"
      },
      "source": [
        "# -- SECTION: DATA SET PRE-PROCESS FOR NAIVE BAYES --\n",
        "\n",
        "# extract the columns labeled as 'bank client data' from our training & testing sets\n",
        "bank_client_data_balanced_training_set = balanced_training_set[bank_client_data_columns]\n",
        "\n",
        "balanced_age_series_as_decades = pd.cut(bank_client_data_balanced_training_set['age'], bins=decades)\n",
        "\n",
        "bank_client_data_balanced_training_set_with_bins = bank_client_data_balanced_training_set.copy(deep=True)\n",
        "bank_client_data_balanced_training_set_with_bins['age'] = balanced_age_series_as_decades\n",
        "\n",
        "# encode our categorical variables\n",
        "encoded_balanced_training_set_with_bins = pd.get_dummies(bank_client_data_balanced_training_set_with_bins, drop_first=True)\n",
        "\n",
        "# -- SECTION: RETRAIN CNB WITH BALANCED AND ENCODED DATA --\n",
        "balanced_cnb = CategoricalNB()\n",
        "balanced_cnb.fit(encoded_balanced_training_set_with_bins, balanced_training_set_y)\n",
        "\n",
        "print(balanced_cnb.score(encoded_balanced_training_set_with_bins, balanced_training_set_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6044673446815398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZvqYaZVmdUE",
        "outputId": "242e1679-8da9-4fbe-f6b3-e6cc0231f7f1"
      },
      "source": [
        "# -- SECTION: RETRAINED CNB MATRIX, ROC_AUC --\n",
        "\n",
        "# create a confusion matrix with our Categorical Naive Bayes classifier\n",
        "cnb_balanced_training_predictions = balanced_cnb.predict(encoded_balanced_training_set_with_bins)\n",
        "\n",
        "# create our cnb confusion matrix\n",
        "print(confusion_matrix(balanced_training_set_y, cnb_balanced_training_predictions))\n",
        "\n",
        "cnb_balanced_training_predictions[cnb_balanced_training_predictions == 'no'] = 0\n",
        "cnb_balanced_training_predictions[cnb_balanced_training_predictions == 'yes'] = 1\n",
        "cnb_balanced_training_predictions = cnb_balanced_training_predictions.astype(int)\n",
        "\n",
        "# score our cnb confusion matrix\n",
        "print(roc_auc_score(balanced_training_set_y, cnb_balanced_training_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[11552  6981]\n",
            " [ 7681 10855]]\n",
            "0.6044688703520166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMpf9wDcnroi",
        "outputId": "3d571ca2-42de-4f91-b0f3-2909e67dcf1a"
      },
      "source": [
        "# -- SECTION: DATA SET PRE-PROCESS FOR KNeighbors CLASSIFIER  --\n",
        "\n",
        "encoded_balanced_training_set = pd.get_dummies(bank_client_data_balanced_training_set, drop_first=True)\n",
        "\n",
        "balanced_knb = KNeighborsClassifier()\n",
        "balanced_knb.fit(encoded_balanced_training_set, balanced_training_set_y)\n",
        "\n",
        "print(knb.score(encoded_balanced_training_set, balanced_training_set_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5582832015970217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZf4mh1Ho6rO",
        "outputId": "8a94d5b0-256b-424a-bfd8-b1e4e71b96c2"
      },
      "source": [
        "# -- SECTION: RETRAINED KNeighbors MATRIX, ROC_AUC --\n",
        "\n",
        "# create a confusion matrix with our KNeighbors Classifier\n",
        "knb_balanced_training_predictions = balanced_knb.predict(encoded_balanced_training_set)\n",
        "\n",
        "# create our knb confusion matrix\n",
        "print(confusion_matrix(balanced_training_set_y, knb_balanced_training_predictions))\n",
        "\n",
        "knb_balanced_training_predictions[knb_balanced_training_predictions == 'no'] = 0\n",
        "knb_balanced_training_predictions[knb_balanced_training_predictions == 'yes'] = 1\n",
        "knb_balanced_training_predictions = knb_balanced_training_predictions.astype(int)\n",
        "\n",
        "# score our knb confusion matrix\n",
        "print(roc_auc_score(balanced_training_set_y, knb_balanced_training_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[13216  5317]\n",
            " [ 2977 15559]]\n",
            "0.7762499816317572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P93bKzvqqPRL",
        "outputId": "2c3f5fd7-9726-4ec7-f105-8b489a3a23a7"
      },
      "source": [
        "# -- SECTION: Gaussian Naive Bayes --\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "social_and_economic_data_columns = ['emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
        "\n",
        "social_and_economic_training_set = training_set[social_and_economic_data_columns]\n",
        "social_and_economic_testing_set = testing_set[social_and_economic_data_columns]\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(social_and_economic_training_set, training_set_y)\n",
        "\n",
        "print(gnb.score(social_and_economic_training_set, training_set_y))\n",
        "print(gnb.score(social_and_economic_testing_set, testing_set_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7199816558310178\n",
            "0.7193493566399611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tosEY_xyrlEO",
        "outputId": "ce6560a1-d2ed-4ad5-ee41-abbe0a3753d0"
      },
      "source": [
        "# -- SECTION: Gaussian Naive Bayes MATRIX, ROC_AUC --\n",
        "\n",
        "# create a confusion matrix with our KNeighbors Classifier\n",
        "gnb_training_predictions = gnb.predict(social_and_economic_training_set)\n",
        "\n",
        "# create our knb confusion matrix\n",
        "print(confusion_matrix(training_set_y, gnb_training_predictions))\n",
        "\n",
        "gnb_training_predictions[gnb_training_predictions == 'no'] = 0\n",
        "gnb_training_predictions[gnb_training_predictions == 'yes'] = 1\n",
        "gnb_training_predictions = gnb_training_predictions.astype(int)\n",
        "\n",
        "# score our knb confusion matrix\n",
        "print(roc_auc_score(training_set_y, gnb_training_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[23717  9185]\n",
            " [ 1195  2972]]\n",
            "0.7170302906069623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYGvGuMzzUM7"
      },
      "source": [
        "The K Neighbors classifier performed the best with an AUC score of 0.7762499816317572\n",
        "."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAbzfghQuuoM"
      },
      "source": [
        "##**Experiment 14**: Using Gaussian Naive Bayes to  check quantitive features of \"social and economic context attributes\". We then use the score, confusion matrix, and AUC, and then see how well data predicts the response. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ungDtuUTsKtT",
        "outputId": "c74312ee-0913-4491-b7be-ab0bd9c83a3a"
      },
      "source": [
        "# -- SECTION: Balanced Gaussian Naive Bayes --\n",
        "\n",
        "balanced_social_and_economic_training_set = balanced_training_set[social_and_economic_data_columns]\n",
        "\n",
        "balanced_gnb = GaussianNB()\n",
        "balanced_gnb.fit(balanced_social_and_economic_training_set, balanced_training_set_y)\n",
        "\n",
        "print(gnb.score(balanced_social_and_economic_training_set, balanced_training_set_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7190644473819094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sVcXcvBznOQ"
      },
      "source": [
        "The data predicts the reponse well with a score of 0.7190644473819094\n",
        "."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqwc7D7Buxyr"
      },
      "source": [
        "##**Experiment 15**: Check if results of the last experiement changed if training set is balanced. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YydQ5_SisN_J",
        "outputId": "10a64734-ae86-4d60-fa84-4bca5ee773e6"
      },
      "source": [
        "# -- SECTION: Balanced Gaussian Naive Bayes MATRIX, ROC_AUC --\n",
        "\n",
        "# create a confusion matrix with our KNeighbors Classifier\n",
        "gnb_balanced_training_predictions = balanced_gnb.predict(balanced_social_and_economic_training_set)\n",
        "\n",
        "# create our knb confusion matrix\n",
        "print(confusion_matrix(balanced_training_set_y, gnb_balanced_training_predictions))\n",
        "\n",
        "gnb_balanced_training_predictions[gnb_balanced_training_predictions == 'no'] = 0\n",
        "gnb_balanced_training_predictions[gnb_balanced_training_predictions == 'yes'] = 1\n",
        "gnb_balanced_training_predictions = gnb_balanced_training_predictions.astype(int)\n",
        "\n",
        "# score our knb confusion matrix\n",
        "print(roc_auc_score(balanced_training_set_y, gnb_balanced_training_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[13445  5088]\n",
            " [ 5326 13210]]\n",
            "0.7190649651506402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNx7jRd2zz9S"
      },
      "source": [
        "The results of the last experiment changed to 0.7190649651506402. This change was negligible. "
      ]
    }
  ]
}